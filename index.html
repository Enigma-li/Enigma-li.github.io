<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
    <!--meta data-->
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="keywords" content="Changjian Li, Changjian, Homepage, Changjian Li - Homepage, University of Edinburgh, Schoole of Informatics, IPAB, Institute of Perception, Action and Behaviour (IPAB), Institute of Perception, Action and Behaviour, The University of Hong Kong, HKU, HKU CS, ÊùéÊòåÂÅ•, sketch-based modeling, modeling, sketch, computer graphics, geometry, medical image processing">
    <meta name="description" content="Changjian Li's Homepage">
	<!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
	
    <link rel="stylesheet" href="./css/jemdoc.css" type="text/css">
    <link rel="stylesheet" href="./css/style.css" />

    <style type="text/css">
	</style>
    <title>Changjian Li - Homepage</title>
	<link rel="shortcut icon" href="./people/CJ/icon/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href="./people/CJ/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./people/CJ/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./people/CJ/icon/favicon-16x16.png">
    <link rel="manifest" href="./people/CJ/icon/manifest.json">
    <link rel="mask-icon" href="./people/CJ/icon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="theme-color" content="#ffffff">


    <script src="./scripts/scroll.js"></script>
</head>

<body>

    <!-- Navigation Bar -->
    <div class="navbar-container">
        <nav>
            <div>
                <ul>
                    <li><a onclick="scrollToSection('home')">
                        <div class="clickable-area">Home</div>
                    </a></li>
                    <li><a onclick="scrollToSection('biography')">
                        <div class="clickable-area">Biography</div>
                    </a></li>
                    <li><a onclick="scrollToSection('news')">
                        <div class="clickable-area">News</div>
                    </a></li>
                    <li><a onclick="scrollToSection('publication')">
                        <div class="clickable-area">Publication</div>
                    </a></li>
                    <li><a onclick="scrollToSection('team')">
                        <div class="clickable-area">Team</div>
                    </a></li>
                    <li><a onclick="scrollToSection('teaching')">
                        <div class="clickable-area">Teaching</div>
                    </a></li>
                    <li><a onclick="scrollToSection('talks')">
                        <div class="clickable-area">Talks</div>
                    </a></li>
                    <li><a onclick="scrollToSection('service')">
                        <div class="clickable-area">Service</div>
                    </a></li>
                </ul>
            </div>
        </nav>
    </div>

    <!-- Overall layout control -->
    <div id="layout-content" style="margin-top: 25px">
        <!-- Figure, Name, Addree, Email, CV, etc. -->
        <table id="home" class="home">
            <tbody>
                <tr>
                    <td width="19%" valign="top" height="173">
                        <img height="360" id="photo" style="padding: 10pt 30pt 0pt 10pt; float: left; display: inline;" src="./people/CJ/avatar_8.jpg">
                    </td>

                    <td width="80%" valign="top" height="173">
                        <b><font face="Verdana" size="6">Changjian Li (ÊùéÊòåÂÅ•)</font></b>
                        <br>
                        <br>
                        <p>
                            <b><font size="5">Assistant Professor</font></b>
                        </p>
                        <p>
                            <a href="https://web.inf.ed.ac.uk/ipab" target="_blank">Institute of Perception, Action and Behaviour (IPAB)</a><br>
                            <a href="https://www.ed.ac.uk/informatics" target="_blank">School of Informatics</a><br>
                            <a href="https://www.ed.ac.uk/" target="_blank">University of Edinburgh</a>
                            <br>
                            <br>
                            <strong>Address:</strong><br>
                            Room 1.10, Informatics Forum, 
                            <br>
                            10 Crichton Street, Edinburgh,
                            <br>
                            EH8 9AB, United Kingdom
                            <br>
                            <br>
                            <strong>Email:</strong> Changjian.li@ed.ac.uk <br>
                            <br>
                            <a href="./Changjian_cv.pdf" target="_blank">[CV]</a> &nbsp&nbsp <a href="https://scholar.google.com.hk/citations?user=aCgyQsQAAAAJ&hl=en" target="_blank">[Google Scholar]</a> &nbsp&nbsp <a href="https://www.research.ed.ac.uk/en/persons/changjian-li" target="_blank">[Edinburgh PURE]</a>
                        </p>
                    </td>
                </tr>
            </tbody>
        </table>

        <!-- Biography -->
        <h2 id="biography">Biography</h2>
        <p style="text-align: justify; line-height: 1.5;">
            I am an Assistant Professor in the School of Informatics at the University of Edinburgh. I have a board range of research interests in <strong>3D Shape Creation and Analysis</strong> with applications in Sketch-based Modeling, Shape Reconstruction and Analysis from Point Clouds, and Medical Image Processing and Modeling. For sketch-based modeling (my representative line of research), we have recently developed two systems for easier CAD modeling by combining the advanced neural network and traditional optimization, where we translate intuitive sketches into CAD programs that greatly facilitate the downstream applications. 
        </p>
        <p style="text-align: justify; line-height: 1.5;">
            Before joining University of Edinburgh, I worked at Inria as a Starting Researcher working with Dr. <a href="http://www-sop.inria.fr/members/Adrien.Bousseau/" target="_blank ">Adrien Bousseau</a> and did my postdoc in the Smart Geometry Processing Group at University College London (UCL) working with <a href="http://www0.cs.ucl.ac.uk/staff/n.mitra/index.html" target="_blank">Prof. Niloy Mitra</a>. I got my Ph.D. degree from the University of Hong Kong in 2019 supervised by <a href="http://i.cs.hku.hk/~wenping/" target="_blank">Prof. Wenping Wang</a> and got my Bachelor degree from Shandong University in 2014.
        </p>
        <p style="text-align: justify; line-height: 1.5;">
            <strong style="color:red; font-size:120%;">Accepting Students</strong>: I am looking for highly motivated students, feel free to drop me an email with your CV. <br>
            <!-- <span class="dot">&#8226;</span> We are recruiting a Postdoc working on <strong>Generative AI</strong>. Email me for details. -->
        </p>

        <!-- News -->
        <h2 id="news">News</h2>
        <div class="news-container">
            <div class="scrollable-content">
                <span class="dot">&#8226;</span> 07/28, 2024: We have <strong>one</strong> paper accepted to <strong>Siggraph Asia 2024</strong>, congratulations to <strong>Haocheng</strong>! üéâüéâüéâ<br>
                <span class="dot">&#8226;</span> 04/05, 2024: CADTalk was selected as <strong>Hightlight</strong> in the coming CVPR 2024. üéâüéâüéâ<br>
                <span class="dot">&#8226;</span> 02/26, 2024: We have <strong>three</strong> papers accepted to <strong>CVPR 2024</strong>, congratulations to <strong>Haocheng, Ankan</strong> and <strong>Jiawei</strong>! <br>
                <span class="dot">&#8226;</span> 10/11, 2023: We recruiting a Postdoc working on 3D Vision and representation learning. <br> <!--Check out<strong><a href="https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/9432" target="_blank"> the link</a></strong> here. -->
                <span class="dot">&#8226;</span> 10/11, 2023: We have one paper accepted to TVCG for point cloud upsampling, congratulation to Guangshun! <br>
                <span class="dot">&#8226;</span> 10/01, 2023: Welcome Miaowei to join the School of Informatics. <br>
                <span class="dot">&#8226;</span> 09/10, 2023: Welcome Haocheng, Yue, Mingjun, and Jing to join our group. <br>
                <span class="dot">&#8226;</span> 05/10, 2023: Welcome Ankan to join the School of Informatics. <br>
                <span class="dot">&#8226;</span> 10/20, 2022: I have joined the University of Edinburgh as an Assistant Professor.<br>
            </div>
        </div>

        <!-- Publication -->
        <h2 id="publication">Publications</h2>
        # Corresponding author; * Equal contribution
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- DiffCSG: Differentiable CSG via Rasterization -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="260" style="padding: 0pt 10pt 0pt 0pt" src="./projects/diffCSG/diffcsg_icon.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">DiffCSG: Differentiable CSG via Rasterization</font>
                        <br>
                        Haocheng Yuan, Adrien Bousseau, Hao Pan, Chengquan Zhang, Niloy Mitra, <strong>Changjian Li</strong>. &nbsp;
                        <br>
                        [<a href="https://yyyyyhc.github.io/DiffCSG/" target="_blank">Project page</a>]&nbsp;
                        [<a href="https://arxiv.org/pdf/2409.01421" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code</a>]&nbsp 
                        [<a href="" target="_blank">Video</a>]<br>
                        <p style="color:red;font-size:60%;"> </p>
                        <p style="color:red;font-size:100%;"> <em>Conditionally accepted to Siggraph Asia 2024!</em></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Odd-One-Out: Anomaly Detection by Comparing with Neighbors -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/oddOneOut/O3_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Odd-One-Out: Anomaly Detection by Comparing with Neighbors</font>
                        <br>
                        Ankan Bhunia, <strong>Changjian Li</strong>,  Hakan Bilen. &nbsp; <em>ArXiv Prepint, 2024.</em><br>
                        [<a href="https://groups.inf.ed.ac.uk/vico/research/Odd-One-Out/" target="_blank">Project Page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/2406.20099" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/VICO-UoE/OddOneOutAD" target="_blank">Code</a>]&nbsp;
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Canonical Consolidation Fields: Reconstructing Dynamic Shapes from Point Clouds -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/canField/canField_icon.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Canonical Consolidation Fields: Reconstructing Dynamic Shapes from Point Clouds</font>
                        <br>
                        Miaowei Wang, <strong>Changjian Li</strong>, Amir Vaxman. &nbsp; <em>ArXiv Prepint, 2024.</em><br>
                        [<a href="https://arxiv.org/abs/2406.18582" target="_blank">Paper</a>]
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="260" style="padding: 0pt 10pt 0pt 0pt" src="./projects/cadtalk/cadtalk_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs</font>
                        <br>
                        Haocheng Yuan, Jing Xu, Hao Pan, Adrien Bousseau, Niloy Mitra, <strong>Changjian Li</strong>. &nbsp;<em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024. </em> 
                        <br>
                        [<a href="https://enigma-li.github.io/CADTalk/" target="_blank">Project page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/2311.16703" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/YYYYYHC/CADTalk" target="_blank">Code</a>]&nbsp;
                        [<a href="https://enigma-li.github.io/CADTalk/resources/cadtalk_dataset.html" target="_blank">Dataset</a>]&nbsp;
                        [<a href="https://www.youtube.com/watch?v=83Fnvj2H0_g" target="_blank">Video</a>]<br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <em><strong>Highlight (top 10%)</strong></em> üéâüéâüéâ</p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- ContextSeg: Sketch Semantic Segmentation by Querying the Context with Attention -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/contextSeg/contextSeg_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">ContextSeg: Sketch Semantic Segmentation by Querying the Context with Attention</font>
                        <br>
                        Jiawei Wang, <strong>Changjian Li</strong>. &nbsp;<em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024. </em> 
                        <br>
                        [<a href="./projects/contextSeg/contextSeg.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/2311.16682" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/JiaWei22/ContextSeg" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="https://www.youtube.com/watch?v=k_yq-Y7YAVk" target="_blank">Video</a>]&nbsp;
                        <!-- [<a href="https://doi.ieeecomputersociety.org/10.1109/TVCG.2023.3324924" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Looking 3D: Anomaly Detection with 2D-3D Alignment -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/look3D/look3D_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Looking 3D: Anomaly Detection with 2D-3D Alignment</font>
                        <br>
                        Ankan Bhunia, <strong>Changjian Li</strong>, Hakan Bilen. &nbsp;<em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024. </em> 
                        <br>
                        [<a href="https://groups.inf.ed.ac.uk/vico/research/Looking3D/" target="_blank">Project page</a>]&nbsp;
                        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Bhunia_Looking_3D_Anomaly_Detection_with_2D-3D_Alignment_CVPR_2024_paper.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/VICO-UoE/Looking3D" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="https://www.youtube.com/watch?v=45Hum8efMPg" target="_blank">Video</a>]&nbsp;
                        <!-- [<a href="https://doi.ieeecomputersociety.org/10.1109/TVCG.2023.3324924" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- iPUNet: Iterative Cross Field Guided Point Cloud Upsampling -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/iPUNet/iPUNet_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">iPUNet: Iterative Cross Field Guided Point Cloud Upsampling</font>
                        <br>
                        Guangshun Wei, Hao Pan, Shaojie Zhuang, Yuanfeng Zhou, <strong>Changjian Li</strong>. &nbsp;<em> IEEE Visualization and Computer Graphics (TVCG)</em>, 2023.<br>
                        [<a href="./projects/iPUNet/iPUNet.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/2310.09092" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/GSW-D/iPUNet" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="https://doi.ieeecomputersociety.org/10.1109/TVCG.2023.3324924" target="_blank">DOI</a>]<br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Geometry-Aware Attenuation Field Learning for Sparse-View CBCT Reconstruction -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="290" style="padding: 0pt 10pt 0pt 0pt" src="./projects/CBCTRecon_GeoAware/icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Geometry-Aware Attenuation Field Learning for Sparse-View CBCT Reconstruction</font>
                        <br>
                        Zhentao Liu, Yu Fang, <strong>Changjian Li</strong>, Han Wu, Yuan Liu, Zhiming Cui, Dinggang Shen. <br>
                         ArXiv Prepint, 2023.<br>
                        [<a href="https://arxiv.org/abs/2303.14739" target="_blank">Paper</a>]
                        <!-- [<a href="https://ns.inria.fr/d3/cad2sketch/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/cad2sketch/CAD2Sketch_SIGA_2022.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code,Data (Comming soon...)</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3550454.3555488" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- SNAF: Sparse-view CBCT Reconstruction with Neural Attenuation Fields -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="260" style="padding: 0pt 10pt 0pt 0pt" src="./projects/CBCTRecons/snaf_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">SNAF: Sparse-view CBCT Reconstruction with Neural Attenuation Fields</font>
                        <br>
                        Yu Fang, Lanzhuju Mei, <strong>Changjian Li</strong>, Yuan Liu, Wenping Wang, Zhiming Cui, Dinggang Shen. <br>
                        ArXiv Prepint, 2022.<br>
                        [<a href="https://arxiv.org/abs/2211.17048" target="_blank">Paper</a>]
                        <!-- [<a href="https://ns.inria.fr/d3/cad2sketch/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/cad2sketch/CAD2Sketch_SIGA_2022.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code,Data (Comming soon...)</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3550454.3555488" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- ToothInpaintor: Tooth Inpainting from Partial 3D Dental Model and 2D Panoramic Image -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/toothInpainter/toothInpaintor_icon.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">ToothInpaintor: Tooth Inpainting from Partial 3D Dental Model and 2D Panoramic Image</font>
                        <br>
                        Yuezhi Yang, Zhiming Cui, <strong>Changjian Li</strong>, Wenping Wang. <br>
                        ArXiv Prepint, 2022.<br>
                        [<a href="https://arxiv.org/abs/2211.15502" target="_blank">paper</a>]
                        <!-- [<a href="https://ns.inria.fr/d3/cad2sketch/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/cad2sketch/CAD2Sketch_SIGA_2022.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code,Data (Comming soon...)</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3550454.3555488" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- CAD2Sketch: Generating Concept Sketches from CAD Sequences -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/cad2sketch/CAD2Sketch_icon.jpeg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">CAD2Sketch: Generating Concept Sketches from CAD Sequences</font>
                        <br>
                        Felix H√§hnlein, <strong>Changjian Li</strong>, Niloy Mitra, Adrien Bousseau. &nbsp;<em>ACM Transaction on Graphics, 41(6), 2022, proceedings of SIGGRAPH Asia 2022. </em><br>
                        [<a href="https://ns.inria.fr/d3/cad2sketch/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/cad2sketch/CAD2Sketch_SIGA_2022.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://gitlab.inria.fr/D3/cad2sketch" target="_blank">Code</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3550454.3555488" target="_blank">DOI</a>]<br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Free2CAD: Parsing Freehand Drawings into CAD Commands -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/free2cad/free2cad_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Free2CAD: Parsing Freehand Drawings into CAD Commands</font>
                        <br>
                        <strong>Changjian Li</strong>, Hao Pan, Adrien Bousseau, Niloy Mitra. &nbsp;<em>ACM Transaction on Graphics, 41(4), 2022, proceedings of SIGGRAPH 2022. </em><br>
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2022/free2cad/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/free2cad/Free2CAD_SIG_2022.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/Enigma-li/Free2CAD" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="./projects/free2cad/Free2CAD_supl.pdf" target="_blank">Supl</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3528223.3530133" target="_blank">DOI</a>]<br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <em><a href="https://blog.siggraph.org/2022/07/siggraph-2022-technical-papers-awards-best-papers-and-honorable-mentions.html/" target="_blank" style="color:#FF0000;"><strong>Best Paper Honorable Mention Award</strong></a></em></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- VertNet: Accurate Vertebra Localization and Identification Network from CT Images -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/vertNet/vertNet_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">VertNet: Accurate Vertebra Localization and Identification Network from CT Images</font>
                        <br>
                        Zhiming Cui, <strong>Changjian Li</strong>, Lei Yang, Chunfeng Lian, Feng Shi, Wenping Wang, Dijia Wu, Dinggang Shen. International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2021. <br>
                        [<a href="./projects/vertNet/VertNet.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="./projects/vertNet/VertNet_MICCAI_2021.pdf" target="_blank">Paper</a>]&nbsp;</br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Structure-Driven Unsupervised Domain Adaptation for Cross-Modality Cardiac Segmentation -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/cardiactSeg/cardiacSeg_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Structure-Driven Unsupervised Domain Adaptation for Cross-Modality Cardiac Segmentation</font>
                        <br>
                        Zhiming Cui, <strong>Changjian Li</strong>, Zhixu Du, Nenglun Chen, Guodong Wei, Runnan Chen, Lei Yang, Wenping Wang. IEEE Transactions on Medical Imaging (TMI), 2021. <br>
                        [<a href="./projects/cardiactSeg/cardiacSeg.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="./projects/cardiactSeg/src/CardiacSeg_DomainAdaptation_TMI_2021.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code</a>]&nbsp;</br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- ScaffoldGAN: Synthesis of Scaffold Materials based on Generative Adversarial Networks -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/scaffoldGAN/scaffoldGAN_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">ScaffoldGAN: Synthesis of Scaffold Materials based on Generative Adversarial Networks</font>
                        <br>
                        Hui Zhang, Lei Yang, <strong>Changjian Li</strong>, Bojian Wu, Wenping Wang. Computer-Aided Design (CAD), 2021. <br>
                        [<a href="./projects/scaffoldGAN/ScaffoldGAN_CAD_2021.pdf" target="_blank">Paper</a>]&nbsp;</br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Hierarchical Morphology-Guided Tooth Instance Segmentation from CBCT Images -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/skeleToothSeg/skeleToothSeg_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Hierarchical Morphology-Guided Tooth Instance Segmentation from CBCT Images</font>
                        <br>
                        Zhiming Cui<sup>*</sup>, Bojun Zhang<sup>*</sup>, Chunfeng Lian, <strong>Changjian Li<sup>#</sup></strong>, Lei Yang, Min Zhu<sup>#</sup>, Wenping Wang, Dinggang Shen<sup>#</sup>. Information Processing in Medical Imaging (IPMI), 2021. <br>
                        [<a href="./projects/skeleToothSeg/skele_tseg.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="./projects/skeleToothSeg/src/ToothSeg_IMPI_2021.pdf" target="_blank">Paper</a>]&nbsp;</br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <em><strong>Oral Presentation</strong></em></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Point2Skeleton: Learning Skeletal Representations from Point Clouds -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/point2skeleton/p2s_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Point2Skeleton: Learning Skeletal Representations from Point Clouds</font>
                        <br>
                        Cheng Lin, <strong>Changjian Li<sup>#</sup></strong>, Yuan Liu, Nenglun Chen, Yi-King Choi, Wenping Wang<sup>#</sup>. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021. <br>
                        [<a href="./projects/point2skeleton/point2skeleton.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Point2Skeleton_Learning_Skeletal_Representations_from_Point_Clouds_CVPR_2021_paper.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/clinplayer/Point2Skeleton" target="_blank">Code</a>]&nbsp; </br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <em><strong>Oral Presentation, Best Paper Candidate</strong></em></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- TSegNet: an Efficient and Accurate Tooth Segmentation Network on 3D Dental Model -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/tsegNet/tseg_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">TSegNet: an Efficient and Accurate Tooth Segmentation Network on 3D Dental Model</font>
                        <br>
                        Zhiming Cui, <strong>Changjian Li</strong>, Nenglun Chen, Guodong Wei, Runnan Chen, Yuanfeng Zhou, Dinggang Shen, Wenping Wang.&nbsp;<em> Medical Image Analysis (MIA) </em>, 2021<br>
                        [<a href="./projects/tsegNet/TSegNet.html" target="_blank">Project Page</a>]
                        [<a href="./projects/tsegNet/paper/TSegNet_MIA_2021.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code</a>]
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- RigidFusion: RGB-D Scene Reconstruction with Rigidly-moving Objects -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="290" style="padding: 0pt 10pt 0pt 0pt" src="./projects/rigidFusion/rigidFusion_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">RigidFusion: RGB-D Scene Reconstruction with Rigidly-moving Objects</font>
                        <br>
                        Yushiang Wong, <strong>Changjian Li</strong>, Matthias Niessner, Niloy Mitra. &nbsp&nbsp&nbsp;<em> Eurographics (EG) </em>, 2021.<br>
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2021/rigidfusion/" target="_blank">Project Page</a>]&nbsp;
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2021/rigidfusion/paper_docs/rigidfusion_eg21.pdf" target="_blank">Paper</a>]&nbsp;
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- SEG-MAT: 3D Shape Segmentation Using Medial Axis Transform -->
                <tr>
                    <td>
                        <div align="center">
                            <img height="120" style="padding: 0pt 10pt 0pt 0pt" src="./projects/segmat/segmat_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">SEG-MAT: 3D Shape Segmentation Using Medial Axis Transform</font>
                        <br>
                        Cheng Lin, Lingjie Liu, <strong>Changjian Li</strong>, Leif Kobbelt, Bin Wang, Shiqing Xin, Wenping Wang. &nbsp;<em> IEEE Visualization and Computer Graphics (TVCG)</em>, 2020<br>
                        [<a href="./projects/segmat/SEG-MAT.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/2010.11488" target="_blank">arXiv Preprint</a>]
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Sketch2CAD: Sequential CAD Modeling by Sketching in Context -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/sketch2cad/sketch2cad_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Sketch2CAD: Sequential CAD Modeling by Sketching in Context</font>
                        <br>
                        <strong>Changjian Li</strong>, Hao Pan, Adrien Bousseau, Niloy Mitra. &nbsp;<em>ACM Trans. Graph., 39(6), 2020, proceedings of SIGGRAPH Asia 2020</em><br>
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2020/sketch2cad/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/sketch2cad/Sketch2CAD_SIGA_2020.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/Enigma-li/Sketch2CAD" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="./projects/sketch2cad/Sketch2CAD_supl.pdf" target="_blank">Supl</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3414685.3417807" target="_blank">DOI</a>]<br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Floorplan-Jigsaw: Jointly Estimating Scene Layout and Aligning Partial Scans -->
                <tr>
                    <td>
                        <div align="center">
                            <img height="150" style="padding: 0pt 10pt 0pt 0pt" src="./projects/indoorRecons/indoor_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Floorplan-Jigsaw: Jointly Estimating Scene Layout and Aligning Partial Scans</font>
                        <br>
                        Cheng Lin, <strong>Changjian Li</strong>, Wenping Wang. &nbsp;<em> International Conference on Computer Vision (ICCV)</em>, 2019<br>
                        [<a href="./projects/indoorRecons/floorplanJigsaw.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/1812.06677" target="_blank">arXiv</a>]
                        [<a href="./projects/indoorRecons/src/paper/floorplanJigsaw_ICCV2019.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="./projects/indoorRecons/src/supl/floorplanJigsaw_ICCV2019_Supplemental_Material.pdf" target="_blank">Supl</a>]&nbsp; </br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"><strong>Our poster session is highlighted in the 'Computer Vision News, The magazine of the algorithm community': <a href="https://www.rsipvision.com/ICCV2019-Friday/16/" target="_blank">ICCV Daily 2019, Friday</a></strong></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- ToothNet: Automatic Tooth Instance Segmentation and Identification from Cone Beam CT Images -->
                <tr>
                    <td>
                        <div align="center">
                            <img height="150" style="padding: 0pt 10pt 0pt 0pt" src="./projects/toothSeg/toothSeg_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">ToothNet: Automatic Tooth Instance Segmentation and Identification from Cone Beam CT Images</font>
                        <br>
                        Zhiming Cui, <strong>Changjian Li</strong>, Wenping Wang. &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. </strong></em><br>
                        [<a href="./projects/toothSeg/toothNet.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/toothSeg/paper/toothNet_CVPR2019.pdf" target="_blank">Paper</a>]&nbsp; </br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <strong>Our poster session is highlighted in the technical news of IEEE Computer Society: <a href="https://www.computer.org/publications/tech-news/events/ieee-conference-on-computer-vision-and-pattern-recognition-2019-poster-sessions" target="_blank">Poster Sessions Provoke Deep Discussions at the 2019 Conference on CVPR.</a> </strong></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling -->
                <tr>
                    <td>
                        <div align="center">
                            <img height="170" style="padding: 0pt 10pt 0pt 0pt" src="./projects/sketchcnn/sketchcnn_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling</font>
                        <br>
                        <strong>Changjian Li</strong>, Hao Pan, Yang Liu, Xin Tong, Alla Sheffer, Wenping Wang. &nbsp;<em>ACM Trans. Graph., 37(6), 2018, proceedings of SIGGRAPH Asia 2018</em><br>
                        [<a href="http://haopan.github.io/sketchCNN.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/sketchcnn/SketchCNN_SIGA_2018.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/Enigma-li/SketchCNN/" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="./projects/sketchcnn/supplemental.pdf" target="_blank">Supl</a>]&nbsp;
                        [<a href="https://dl.acm.org/citation.cfm?id=3275051" target="_blank">DOI</a>]</br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"><strong>Our Teaser image was selected as the <a href="./projects/sketchcnn/cover_image.png"><strong>cover image</strong></a> of Transaction on Graphics of year 2018. And it also was selected by ACM SIGGRAPH Asia for technical paper <a href="https://sa2018.siggraph.org/images/press-releases/SA18%20Tech%20Papers%20PR%20-%2030%20Nov%2018%20-%20Making%20It%20Easier%20To%20Transform%202D%20Sketching%20Into%203D%20Models.pdf"><strong>press release</strong></a> as research highlights. </strong></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- BendSketch: Modeling Freeform Surfaces Through 2D Sketching -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="240" style="padding: 0pt 10pt 0pt 0pt" src="./projects/bendsketching/bendsketch_icon.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">BendSketch: Modeling Freeform Surfaces Through 2D Sketching</font>
                        <br>
                        <strong>Changjian Li</strong>, Hao Pan, Yang Liu, Xin Tong, Alla Sheffer, Wenping Wang. &nbsp;<em>ACM Trans. Graph., 36(4), 2017, proceedings of SIGGRAPH 2017</em><br>
                        [<a href="http://haopan.github.io/bendsketch.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/bendsketching/bendsketch.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="./projects/bendsketching/BendSketchData.zip" target="_blank">Data</a>]
                        <!-- [<a href="">DOI</a>] -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Flow Aligned Surfacing of Curve Networks -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="200" style="padding: 0pt 10pt 0pt 0pt" src="./projects/curvnet_surfacing/curvenet_surfacing_icon.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Flow Aligned Surfacing of Curve Networks</font>
                        <br>
                        Hao Pan, Yang Liu, Alla Sheffer, Nicholas Vining, <strong>Changjian Li</strong>, Wenping Wang. &nbsp;<em>ACM Trans. Graph., 36(4), 2015, proceedings of SIGGRAPH 2015</em><br>
                        [<a href="http://haopan.github.io/curvenet_surfacing.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/curvnet_surfacing/sketch_surface.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="./projects/curvnet_surfacing/curve_surfacing_curves_meshes.zip" target="_blank">Data</a>]
                        <!-- [<a href="">DOI</a>] -->
                    </td>
                </tr>
            </tbody>
        </table>

        <!-- Team -->
        <h2 id="team">Team</h2>
        <div class="table-container">
            <h3>Current Postdocs and Students</h3>
            <table class="content-table">
                <tbody>
                    <tr>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/daniel.jpg" alt=""> <br>
                            <a href="https://danier97.github.io/" target="_blank">Duolikun Danier</a> (Postdoc) <br>
                            (with Oisin and Hakan)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/haocheng.jpg" alt=""> <br>
                            <a href="https://yyyyyhc.github.io/" target="_blank">Haocheng Yuan</a> (PhD) <br>
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/ruanyue.jpg" alt=""> <br>
                            Yue Ruan (PhD)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/leizhong.png" alt=""> <br>
                            <a href="https://zhongleilz.github.io/" target="_blank">Lei Zhong</a> (PhD)
                        </td>
                    </tr>
                    <tr>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/ankan.jpeg" alt=""> <br>
                            <a href="https://ankanbhunia.github.io/" target="_blank">Ankan Bhunia</a> (PhD)<br>
                            (with Hakan, secondary)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/miaowei.JPG" alt=""> <br>
                            <a href="https://www.linkedin.com/in/miaowei-michael-wang-10127620a/" target="_blank">Miaowei Wang</a> (PhD)<br>
                            (with Amir, secondary)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/sal.jpeg" alt=""> <br>
                            <a href="https://salesposito.github.io/" target="_blank">Salvatore Esposito</a> (PhD) <br>
                            (with Arno, Oisin, secondary)
                        </td>
                        <td style="text-align: center;">
                            <!-- placeholder -->
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
        
        <div class="table-container">
            <h3>Visiting and Intern Students</h3>
            <table class="content-table">
                <tbody>
                    <tr>
                        <!-- <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/guangshun.jpg" alt=""> <br>
                            <a href="https://gsw-d.github.io/gswei.github.io/" target="_blank">Guangshun Wei</a> (Postdoc)<br>
                            (Visiting Researcher - remote)
                        </td> -->
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/kuankuan.jpg" alt=""><br>
                            Kuankuan Cheng <br>(Incoming MScR)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/jiawei.jpg" alt=""> <br>
                            <a href="https://jiawei22.github.io/" target="_blank">Jiawei Wang</a> (UG) <br>
                            (Intern Student - remote)
                        </td>
                        <td style="text-align: center;">
                            <!-- placeholder -->
                        </td>
                        <td style="text-align: center;">
                            <!-- placeholder -->
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="table-container2">
            <h3>Former Group Memembers</h3>
            <table >
                <tbody>
                    <tr>
                        <td>Mingjun Yang, MScR@UoE, 2023.09-2024.08. Now:</td>
                        <!-- <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/mingjun.jpg" alt=""> <br>
                            Mingjun Yang (MScR)
                        </td> -->
                    </tr>
                    <tr>
                        <td>Jing Xu, UG@UoE, Intern Student, 2023.09-2023.12. Now:</td>
                    </tr>
                    <tr>
                        <td>Shuyuan Zhang, UG@UoE, Intern Student, 2023.06-2024.05. Now: MSc at Imperial College London</td>
                        <!-- <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/shuyuan.png" alt=""> <br>
                            Shuyuan Zhang (UG) <br>
                            (Intern Student)
                        </td> -->
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- Teaching -->
        <h2 id="teaching">Teaching</h2>
            <table id="tbTeaching" border="0" width="100%">
                <tbody>
                    <tr>
                        <td>2023-2024(S2)</td>
                        <td>INFR11140 - Image and Vision Computing</td>
                        <td>UoE Informatics</td>
                    </tr>
                    <tr>
                        <td>2023-2024(S1)</td>
                        <td>INFR09051 - Informatics Large Practical</td>
                        <td>UoE Informatics</td>
                    </tr>
                    <tr>
                        <td>2020-2021(S2)</td>
                        <td>COMP0119 - Acquisition and Processig of 3D Geometry</td>
                        <td>UCL CS</td>
                    </tr>
                    <tr>
                        <td>2017-2018(S2)</td>
                        <td>COMP2396 - Object Oriented Programming and Java</td>
                        <td>HKU CS</td>
                    </tr>
                    <tr>
                        <td>2016-2017(S1)</td>
                        <td>ENGG1111 - Computer Programming and Applications</td>
                        <td>HKU CS</td>
                    </tr>
                    <tr>
                        <td>2015-2016(S1)</td>
                        <td>COMP7507 - Visualization and Visual Analytics</td>
                        <td>HKU CS</td>
                    </tr>
                    <tr>
                        <td>2014-2015(S1)</td>
                        <td>ENGG1111 - Computer Programming and Applications</td>
                        <td>HKU CS</td>
                    </tr>
                </tbody>
            </table>

        <!-- Research Experience -->
        <!--
        <h2>Research Experiences</h2>
        <table id="tbExperiences" border="0" width="100%">
            <tbody>
                <tr>
					<td>Oct. 2021 - July 2022</td>
					<td>Starting Researcher</td>
					<td><a href="http://www-sop.inria.fr/members/Adrien.Bousseau/" target="_blank">Dr. Adrien Bousseau</a></td>
                </tr>
                <tr>
					<td>Oct. 2019 - Sept. 2021</td>
					<td>Postdoctoral Research Associate</td>
					<td><a href="http://www0.cs.ucl.ac.uk/staff/n.mitra/index.html" target="_blank">Prof. Niloy Mitra</a></td>
                </tr>
                <tr>
					<td>Sept. 2018 - Jan. 2019</td>
					<td>Visiting Graduate Student, University of Toronto</td>
					<td><a href="http://www.cs.toronto.edu/~jacobson/" target="_blank">Prof. Alec Jacobson</a> and <a href="http://diwlevin.webfactional.com/researchdb/" target="_blank">Prof. David Levin</a></td>
                </tr>
                <tr>
					<td>Feb. 2016 &nbsp;- Aug. 2018</td>
					<td>Research Intern <em>(multiple times)</em>, Microsoft Research Asia</td>
					<td><a href="http://haopan.github.io/" target="_blank">Dr. Hao Pan</a> and <a href="https://xueyuhanlang.github.io/" target="_blank">Dr. Yang Liu</a></td>
                </tr>
                <tr>
					<td>Feb. 2014 &nbsp;- May 2014</td>
					<td>Research Assistant, The University of Hong Kong</td>
					<td><a href="http://i.cs.hku.hk/~wenping/" target="_blank">Prof. Wenping Wang</a> and <a href="http://haopan.github.io/" target="_blank">Dr. Hao Pan</a></td>
                </tr>
            </tbody>
        </table>
        -->
		
        <!-- Invited Talk -->
        <h2 id="talks">Invited Talks</h2>
        <table id="tbTalks" border="0" width="100%">
            <tbody>
                <tr>
                    <td><strong>GAMES: Graphics And Mixed Environment Seminar, China</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs.</td>
                    <td>Jun. 2024</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong> <a href="https://sites.google.com/view/eccv-dira/home" target="_blank">Keynote Speaker at DIRA Workshop</a>, ECCV2022, Tel Aviv</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;High-quality CAD modeling via Rough Sketching.</td>					
                    <td>Oct. 2022</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong> <a href="https://irc.cs.sdu.edu.cn/gdc2022/index.html#/ztlt" target="_blank">Invited workshop speaker at GDC</a>, Qingdao, China</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Free2CAD: Parsing Freehand Drawings into CAD Commands.</td>					
                    <td>Aug. 2022</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>School of Software, Tsinghua University, China</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Creating, Analyzing and Processing 3D Data: Applications to interactive 3D modeling and to medical imaging.</td>					
                    <td>Dec. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>School of Informatics, University of Edinburgh, UK</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Creating, Analyzing and Processing 3D Data: Applications to interactive 3D modeling and to medical imaging.</td>					
                    <td>Oct. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>Stanford Human-Computer Interaction group, Stanford</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Sketch2CAD: Sequential CAD Modeling by Sketching in Context.</td>					
                    <td>Jan. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>AI Lab Sharing Session, Autodesk</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Sketch2CAD: Sequential CAD Modeling by Sketching in Context.</td>					
                    <td>Jan. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>Software College, Shandong University, Jinan</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Sketch-based Freeform Surface Modeling.</td>					
                    <td>Oct. 2019</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>iDDA, The Chinese University of Hong Kong, Shenzhen</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;SketchAShape: Sketch-based Freeform Surface Modeling.</td>					
                    <td>Jul. 2019</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>IRC Lab, Shandong University</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling.<br>&nbsp;&nbsp;&nbsp;&nbsp;Automatic Tooth Instance Segmentation and Identification from CBCT Images.</td>					
                    <td>Mar. 2019</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>DGP Lab, University of Toronto</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;BendSketch: Modeling Freeform Surfaces Through 2D Sketching.</td> 
                    <td>Sept. 2018</td>
                </tr>
                    <td>
                        <br>
                    </td>
                <tr>
                </tr>
                <tr>
                    <td><strong>GAMES: Graphics And Mixed Environment Seminar, China</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling.</td>
                    <td>Nov. 2018</td>
                </tr>
            </tbody>
        </table>
        
        <!-- Service: Committee, Reviewer, etc. -->
        <h2 id="service">Recent Professional Services</h2>
        <!-- Editorial Posts -->
        <h3>Editorial Posts</h3>
        <table id="tbCommittees" border="0" width="100%">
            <tbody>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; Associate Editor - IEEE TVCG (2024-present)</td>
                </tr>
            </tbody>
        </table>

        <!-- Program Committees -->
        <h3>Committee Service</h3>
        <table id="tbCommittees" border="0" width="100%">
            <tbody>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; SIGGRAPH Asia</td>
                </tr>
                <tr>
                    <td>&emsp;&emsp;&#8226; Technical Program Committee - 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; SIGGRAPH</td>
                </tr>
                <tr>
                    <td>&emsp;&emsp;&#8226; Poster Jury Committee - 2023, 2024</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; EuroGraphics</td>
                </tr>
                <tr>
                    <td>&emsp;&emsp;&#8226; International Program Committee (IPC) - 2025</td>
                </tr>
                <tr>
                    <td>&emsp;&emsp;&#8226; State-of-the-art-report IPC - 2025</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; Geometry Design and Computing (GDC)</td>
                </tr>
                <tr>
                    <td>&emsp;&emsp;&#8226; Technical Program Committee 2022, 2023 </td>
                </tr>
            </tbody>
        </table>
        
        <!-- Reviewer -->
        <h3>Reviewer Service</h3>
        <table id="tbReviewer" border="0" width="100%">
            <tbody>
                <tr>
                    <td>&nbsp;&nbsp;ACM Transaction on Graphics (TOG)</td>
                    <td>2022</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;ACM SIGGRAPH</td>
                    <td>2021-2024</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;ACM SIGGRAPH Asia</td>
                    <td>2015, 2019-2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Conference on Computer Vision and Pattern Recognition (CVPR)</td>
                    <td>2021, 2023, 2024</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;International Conference on Computer Vision (ICCV)</td>
                    <td>2021</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;IEEE Transactions on Visualization & Computer Graphics (TVCG)</td>
                    <td>2020-2024</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Eurographics (EG)</td>
                    <td>2019-2023,2025</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;ACM SIGCHI</td>
                    <td>2020, 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;AAAI</td>
                    <td>2024</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;ACM Symposium on User Interface Software and Technology (UIST)</td>
                    <td>2020</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Computer-Aided Design (CAD)</td>
                    <td>2019, 2022-2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Computer Graphics Forum (CGF)</td>
                    <td>2019</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Journal of Computer Science and Technology (JCST)</td>
                    <td>2019</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Pacific Graphics (PG)</td>
                    <td>2018, 2023, 2024</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Eurographics Symposium on Geometry Processing (SGP)</td>
                    <td>2018</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;International Conference on Computer-Aided Design and Computer Graphics (CAD&CG)</td>
                    <td>2015, 2019</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Geometry Design and Computing (GDC)</td>
                    <td>2022, 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;IEEE Transactions on Image Processing (TIP)</td>
                    <td>2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Journal of Computer Science and Technology (JCST)</td>
                    <td>2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;The Visual Computer (TVCJ)</td>
                    <td>2023</td>
                </tr>
                
            </tbody>
        </table>

        <h4>
            <br>
            <div align="center">
                <b>&copy;Changjian Li.</b>&nbsp; Last update: August, 2024.
            </div
        </h4>
</body>
</html>
